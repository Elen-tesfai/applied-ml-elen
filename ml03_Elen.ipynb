{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d70e6c99",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "\n",
    "**Name:** Elen  \n",
    "**Date:** March 18, 2025\n",
    "\n",
    "## Introduction\n",
    "In this project, we will build machine learning models to predict the survival of passengers on the Titanic. Using the Titanic dataset from Seaborn, we will train multiple classification models: Decision Tree Classifier, Support Vector Machine (SVM), and Neural Network (NN), evaluate their performance, and interpret the results. We will focus on various input features to predict the target variable, \"survived.\"\n",
    "\n",
    "The steps involve data cleaning, feature engineering, model training, performance evaluation, and comparisons. We will explore different feature combinations to observe how they affect the accuracy of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998b28e",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "In this section, we will import the necessary Python libraries to perform data manipulation, model training, and evaluation. These libraries will help us load the Titanic dataset, handle missing values, perform machine learning tasks, and visualize results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b6b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f0c17",
   "metadata": {},
   "source": [
    "## Section 1: Import and Inspect the Data\n",
    "\n",
    "In this section, we will load the Titanic dataset using the `seaborn` library, which provides easy access to the dataset. We'll perform a quick inspection of the data to understand its structure, including the number of rows and columns, data types, and any missing values.\n",
    "\n",
    "### Load Titanic Dataset\n",
    "\n",
    "We will use the `seaborn` library to load the Titanic dataset. This dataset includes information about passengers on the Titanic, including features like age, sex, class, and whether they survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7242f22-168d-4b72-8618-2f3becca0178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64277b9b",
   "metadata": {},
   "source": [
    "## Section 2: Data Exploration and Preparation\n",
    "\n",
    "### 2.1 Handle Missing Values\n",
    "\n",
    "In this step, we will handle any missing values in the dataset. Specifically, we'll impute missing values for the `age` column using the median value of the column, and for the `embark_town` column using the mode (most frequent value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fc7a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after all imputations:\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing 'age' values with the median (since it's a numerical column)\n",
    "titanic['age'] = titanic['age'].fillna(titanic['age'].median())\n",
    "\n",
    "# Fill missing 'embark_town' values with the mode (most frequent value)\n",
    "titanic['embark_town'] = titanic['embark_town'].fillna(titanic['embark_town'].mode()[0])\n",
    "\n",
    "# Handle 'deck' by filling with 'Unknown'\n",
    "# First, check if 'deck' is a categorical column and set the categories before filling\n",
    "if titanic['deck'].dtype.name == 'category':\n",
    "    # Add 'Unknown' as a valid category\n",
    "    titanic['deck'] = titanic['deck'].cat.add_categories(['Unknown'])\n",
    "\n",
    "# Fill missing 'deck' values with 'Unknown'\n",
    "titanic['deck'] = titanic['deck'].fillna('Unknown')\n",
    "\n",
    "# After imputation, check if there are any remaining missing values\n",
    "print(\"\\nMissing values after all imputations:\")\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da43021",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering\n",
    "\n",
    "### Creating New Features:\n",
    "\n",
    "#### **Family Size**:\n",
    "You have already created the `family_size` feature, which combines `sibsp` (siblings/spouses) and `parch` (parents/children) and adds 1 to account for the individual passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b00328a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe4df2",
   "metadata": {},
   "source": [
    "### Age Binning (Optional):\n",
    "You can group passengers into different age categories, like child, adult, senior, etc. This can help capture patterns in the data better than using raw ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7fac597",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 12, 18, 60, 100]\n",
    "labels = ['child', 'teenager', 'adult', 'senior']\n",
    "titanic['age_group'] = pd.cut(titanic['age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d274af",
   "metadata": {},
   "source": [
    "### Create a new column 'age_group' based on the defined bins and labels\n",
    "titanic['age_group'] = pd.cut(titanic['age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdceecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age age_group\n",
      "0  22.0     adult\n",
      "1  38.0     adult\n",
      "2  26.0     adult\n",
      "3  35.0     adult\n",
      "4  35.0     adult\n"
     ]
    }
   ],
   "source": [
    "print(titanic[['age', 'age_group']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc58f5",
   "metadata": {},
   "source": [
    "### Combining Pclass and Embarked (Optional)\n",
    "\n",
    "You can create a new feature `class_embarked` to capture interactions between the two features, `Pclass` (passenger class) and `Embarked` (embarkation port). Here's how to do it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8203d2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass embarked class_embarked\n",
      "0       3  Unknown      3_Unknown\n",
      "1       1  Unknown      1_Unknown\n",
      "2       3  Unknown      3_Unknown\n",
      "3       1  Unknown      1_Unknown\n",
      "4       3  Unknown      3_Unknown\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values in the 'embarked' column with a placeholder (e.g., 'Unknown')\n",
    "titanic['embarked'] = titanic['embarked'].fillna('Unknown')\n",
    "\n",
    "# Create a new feature by combining Pclass and Embarked\n",
    "titanic['class_embarked'] = titanic['pclass'].astype(str) + \"_\" + titanic['embarked'].astype(str)\n",
    "\n",
    "# Check the result\n",
    "print(titanic[['pclass', 'embarked', 'class_embarked']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6d0f5",
   "metadata": {},
   "source": [
    "### 3. Model Training and Evaluation\n",
    "\n",
    "#### 3.1 Split Data into Training and Test Sets\n",
    "You should split the dataset into training and test sets so that you can train your model on the training set and evaluate its performance on the test set. This will help you avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d3a90",
   "metadata": {},
   "source": [
    "### 1. Check the Columns Available in the DataFrame\n",
    "\n",
    "Before proceeding with model training, it's important to inspect the columns available in the dataset to ensure you're referring to the correct columns for feature selection and target variable.\n",
    "\n",
    "You can check the columns in the DataFrame using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a7025a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone', 'family_size', 'age_group', 'class_embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(titanic.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520327d1",
   "metadata": {},
   "source": [
    "### 2. Adjusting the Code\n",
    "\n",
    "After inspecting the columns available in the dataset, we can adjust the code accordingly. The **`name`** column does not exist in the dataset, so we will update the script to exclude only the **`survived`** column (which is the target variable) when splitting the data into training and testing sets.\n",
    "\n",
    "### Updated Script for Splitting Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c28ff9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (X_train, y_train): (712, 17), (712,)\n",
      "Test data shape (X_test, y_test): (179, 17), (179,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and target variable\n",
    "X = titanic.drop(['survived'], axis=1)  # Excluding the target column\n",
    "y = titanic['survived']\n",
    "\n",
    "# Split into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the resulting sets to confirm the split\n",
    "print(f\"Training data shape (X_train, y_train): {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test data shape (X_test, y_test): {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77896e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
